---
title: Projeto prático DSA 2 - Modelo machine learning Analisando dados das casas
  de Boston, nos EUA e fazendo previsoes
output:
  html_document:
    df_print: paged
---

Obs: Caso tenha problemas com a acentuação, consulte este link:
https://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding

- Configurando o diretório de trabalho
- Coloque entre aspas o diretório de trabalho que você está usando no seu computador
- Não use diretórios com espaço no nome

# Base dados
- The Boston Housing Dataset
- http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html

# Definição problema
Seu modelo deve prever a MEDV (Valor da Mediana de ocupação das casas). 
Utilize um modelo de rede neural!

- Definindo o Problema: Analisando dados das casas de Boston, nos EUA e fazendo previsoes.

```{r}
# Carregando o pacote MASS
library(MASS)
```
```{r}
# Resumo dos dados
str(dados)
```
```{r}
summary(dados)
```

# Carregando o pacote para Redes Neurais
#install.packages("neuralnet")
```{r}
library(neuralnet)
```
# Normalizacao

Como primeiro passo, vamos abordar o pré-processamento de dados. 
É uma boa pratica normalizar seus dados antes de treinar uma rede neural. 
Dependendo do seu conjunto de dados, evitando a normalizacao pode levar a 
resultados inuteis ou a um processo de treinamento muito dificil 
(na maioria das vezes o algoritmo não ira convergir antes do numero de iteracoes
maximo permitido). Voce pode escolher diferentes metodos para dimensionar os 
dados (normalizacao-z, escala min-max, etc ...). 
Normalmente escala nos intervalos [0,1] ou [1,1] tende a dar melhores resultados. 

```{r}
# Normalizacao 
maxs <- apply(dados, 2, max) 
mins <- apply(dados, 2, min)
```


```{r}
# Imprimindo os valores
maxs
mins
```


```{r}
# Normalizando
dados_normalizados <- as.data.frame(scale(dados, center = mins, scale = maxs - mins))
head(dados_normalizados)
```

# Criando os dados de treino e de teste
```{r}
#install.packages("caTools")

library(caTools)
```

Dados treino teste
```{r}
split = sample.split(dados_normalizados$medv, SplitRatio = 0.70)
split
```


```{r}
treino = subset(dados_normalizados, split == TRUE)
teste = subset(dados_normalizados, split == FALSE)
```


```{r}
# Obtendo o nome das colunas
coluna_nomes <- names(treino)
coluna_nomes
```


```{r}
# Agregando
formula <- as.formula(paste("medv ~", paste(coluna_nomes[!coluna_nomes %in% "medv"], collapse = " + ")))
formula
```
# Rede neural modelo
ANN
```{r}
# Treinando o Modelo
ANN_model <- neuralnet(formula, data = treino, hidden = c(5,3), linear.output = TRUE)
ANN_model
```


```{r}
# Súmario
summary(ANN_model)
```


```{r}
# Plot
plot(rede_neural)
```


```{r}
# Fazendo previsoes com os dados de teste
rede_neural_prev <- compute(rede_neural, teste[1:13])
rede_neural_prev
```


```{r}
# O retorno da previsao da Rede Neural é uma lista
str(rede_neural_prev)
```


```{r}
# Convertendo os dados de teste
previsoes <- rede_neural_prev$net.result * (max(dados$medv) - min(dados$medv)) + min(dados$medv)
previsoes
```


```{r}
teste_convert <- (teste$medv) * (max(dados$medv) - min(dados$medv)) + min(dados$medv)
teste_convert
```

# MSE
```{r}
# Calculando o Mean Squared Error
MSE.nn <- sum((teste_convert - previsoes)^2)/nrow(teste)
MSE.nn
```


```{r}
# Obtendo os erros de previsao
error.df <- data.frame(teste_convert, previsoes)
head(error.df)
```

# Plot dos erros
```{r}
library(ggplot2)
```


```{r}
ggplot(error.df, aes(x = teste_convert,y = previsoes)) + 
  geom_point() + stat_smooth()
```


```{r}
# Gráfico dos valores da casa
hist(error.df$previsoes,
     col = "blue",
     main = "Gráfico valores das casas",
     xlab = "Casas",
     ylab = "Total")
```