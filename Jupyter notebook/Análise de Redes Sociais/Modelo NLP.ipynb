{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fb2b66",
   "metadata": {},
   "source": [
    "# Modelo processo linguagem natural - Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b01e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão do python\n",
    "from platform import python_version\n",
    "\n",
    "print('Versão Jupyter Notebook neste projeto:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d639a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "\n",
    "# Bibliotecas para NLTK\n",
    "import nltk\n",
    "import re\n",
    "import wordcloud\n",
    "import itertools\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import pandas as pd # Carregamento de arquivos de csv\n",
    "import numpy as np # Carregamento cálculos em arrays multidimensionais\n",
    "\n",
    "# Bibliotecas de visualização\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar as versões das bibliotecas\n",
    "import watermark\n",
    "\n",
    "# Warnings retirar alertas \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando pacote do punkt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verficações da versões das bibliotecas\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Rafael Gallo\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aaffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração fundo dos gráficos e estilo, tamanho da fonte\n",
    "\n",
    "sns.set_palette(\"Accent\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale=1.3)\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c6724",
   "metadata": {},
   "source": [
    "# Base dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed63373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exebindo o 5 primeiro dados \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exebindo o 5 últimos dados\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1012b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de linhas e colunas \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36dd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibido os tipos de dados\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informando as informações e das variaveis \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de colunas e linhas \n",
    "\n",
    "print(\"Rows:\", df.shape[0])\n",
    "print(\"Columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo valores ausentes e Valores únicos\n",
    "\n",
    "print(\"\\nMissing values :  \", df.isnull().sum().values.sum())\n",
    "print(\"\\nUnique values :  \\n\",df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de número duplicados\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ae268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentimento do coluna \n",
    "df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contando números de dados\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baae85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando as colunas do dataset\n",
    "\n",
    "df.columns = [\"Id\",\n",
    "              \"Texto\",\n",
    "              \"Sub_Texto\",\n",
    "              \"Sentimento\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8dc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de dados da coluna na Sentimento\n",
    "df.Sentimento.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de dados da coluna na Sub_Texto\n",
    "df.Sub_Texto.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd243169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos duplicados total\n",
    "\n",
    "df.drop_duplicates([\"Texto\"], inplace = True)\n",
    "df.Texto.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71cb1b",
   "metadata": {},
   "source": [
    "# Análise de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico barras de sentimento\n",
    "plt.figure(figsize=(12.8,6))\n",
    "\n",
    "ax = sns.countplot(df[\"Sentimento\"])\n",
    "plt.title(\"Análise de sentimento\")\n",
    "plt.xlabel(\"Sentimentos\")\n",
    "plt.ylabel(\"Total de sentimentos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965bdd4",
   "metadata": {},
   "source": [
    "# Treino teste\n",
    "- Treino e teste da base de dados da colunas textos e sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[\"Texto\"] # Variável para treino\n",
    "test = df[\"Sentimento\"] # Variável para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de linhas e colunas dados variável x\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de linhas e colunas dados variável y\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e81c3",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbf6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de limpeza para modelo PLN\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Remove stop words: Removendo as stop words na base de dados\n",
    "def remove_stop_words(instancia): # Removendo as stop words\n",
    "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "# Palavras derivacionalmente relacionadas com significados semelhantes, palavras para retornar documentos que contenham outra palavra no conjunto.\n",
    "def text_stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "        return (\" \".join(palavras))\n",
    "\n",
    "# Limpeza na base de dados limpando dados de web com http e outros.\n",
    "def dados_limpos(instancia): \n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return (instancia)\n",
    "\n",
    "#Lemmatization: Em linguística é o processo de agrupar as formas flexionadas de uma palavra para que possam ser analisadas como um único item, identificado pelo lema da palavra , ou forma de dicionário.\n",
    "def Lemmatization(instancia):\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(wordnet_lemmatizer.lemmatize(w))\n",
    "        return (\" \".join(palavras))\n",
    "\n",
    "# Preprocessing: Pré - processamento da base de dados que serão ser para análise de dados.\n",
    "def Preprocessing(instancia):\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('\"','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",  # Search for all non-letters\n",
    "                          \" \",          # Replace all non-letters with spaces\n",
    "                          str(location))\n",
    "\n",
    "# Função para texto de negações\n",
    "def marque_negacao(texto):\n",
    "    \n",
    "    # Negaçoes do texto mudando para not para \"não\"\n",
    "    negacoes = ['não','not']\n",
    "    negacao_detectada = False\n",
    "    \n",
    "    # Criando uma lista vazia \n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    \n",
    "    # For em palavras para os dados de negações \n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    \n",
    "    # Retornando a função\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d779dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base dados limpo\n",
    "train = [Preprocessing(i) for i in train]\n",
    "train[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização as palavras precisam ser codificadas como inteiros, \n",
    "# Ou valores de ponto flutuante, para serem usadas como entradas para modelos machine learning.\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "vet = CountVectorizer(analyzer=\"word\", tokenizer = tokenizer.tokenize)\n",
    "vet_train = vet.fit_transform(train)\n",
    "vet_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25218f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d78ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
